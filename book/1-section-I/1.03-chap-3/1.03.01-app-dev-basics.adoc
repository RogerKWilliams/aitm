==== Basics of applications and their development

===== Defining "Application"

In keeping with our commitment to theory and first princiles, we use an engineering definition of "application." To an electrical engineer, a toaster or a light bulb is an "application" of electricity. Similarly, a customer relationship management system, or a Web video on demand service, are "applications" of the core computer infrastructure we studied in the last chapter.

===== History of applications and application software

Without applications, computers would be merely a curiousity. Computers were first "applied" to military needs for codebreaking and artillery calculations. After World War II, ex-military officers like https://en.wikipedia.org/wiki/Edmund_Berkeley[Edmund Berkeley] at Prudential realized their potential if "applied" to problems like insurance record keeping.

At first, such systems required painstaking programming in complex, tedious, and unforgiving low-level https://en.wikipedia.org/wiki/Programming_language[programming languages]. As the value of computers became increasingly obvious, more investment was committed to more easy to use applications.

CITES

The  https://en.wikipedia.org/wiki/History_of_software[history of software] is well documented. Low level languages (https://en.wikipedia.org/wiki/Binary_code[binary] and https://en.wikipedia.org/wiki/Binary_code[assembler]) became higher level languages (https://en.wikipedia.org/wiki/Fortran[FORTAN], https://en.wikipedia.org/wiki/COBOL[COBOL], https://en.wikipedia.org/wiki/C_(programming_language)[C]). At the end of the day, the objective remains to create a https://en.wikipedia.org/wiki/Executable[binary executable] file or files that computer hardware can "execute," that is, turn into a computing-based value experience, mediated through devices such as laptops, cell phones, and their constituent components.

===== Applications and infrastructure: the old way

In the first decades of computing, any significant appication of computing power to a new problem typically required its own infrastructure, often designed specifically for the problem. While computer scientists always were aware that computers in theory could be "general purpose," in practice this was not so easy. Military/aerospace needs differed from industry, which differed from scientific and technical uses. And major new applications required new compute capacity.

So, for example, when a corporation in 1998 decided to replace its mainframe Human Resources system due to https://en.wikipedia.org/wiki/Year_2000_problem[Y2K concerns]. Such a system might need to support several thousand users around the world. At that time, PeopleSoft was a frequent choice of software. Implementing such a system was often led by consulting firms such as Deloitte or Andersen Consulting (where the author worked).

A typical PeopleSoft package implementation would include:

* https://en.wikipedia.org/wiki/PeopleSoft[PeopleSoft] software, including the PeopleTools framework and various modules written in the framework (e.g. the well-regarded PeopleSoft HR system)
* https://en.wikipedia.org/wiki/Oracle_Database[Oracle database] software
* AT&T "Tuxedo" https://en.wikipedia.org/wiki/Transaction_processing[transaction manager]
* Autosys https://en.wikipedia.org/wiki/Job_scheduler[job scheduler]
* https://en.wikipedia.org/wiki/HP-UX[HP-UX operating system]
* HP-UX servers, perhaps 20 or so, comprising various "environments" including a production "cluster" consisting of application and database servers
* https://en.wikipedia.org/wiki/EMC_Corporation[EMC] storage array
* Various ancillary software and hardware: management utilities and scripts, backup, networking, etc.
* Customization of the PeopleSoft HR module and reports by hired consultants, to meet the requirements of the acquiring organization

The software and hardware needed to be specified in keeping with requirements, and acquiring it took lengthy negotiations and logistics and installation processes. Such a project from inception to production might take 9 months (on the short side) to 18 or more months.

Hardware was dedicated and rarely re-used. The HP servers compatible with PeopleSoft might have few other applications, if they became surplus. In fact, PeopleSoft would "certify" the infrastructure for compatibility. Upgrading the software might require also upgrading the hardware.

In essence, this was more akin to https://en.wikipedia.org/wiki/Systems_engineering[systems engineering], as designing and optimizing the hardware component was a significant portion of the work.

===== Applications and infrastructure today
Today, matters are quite different, and yet echoes of the older model persist. As mentioned, ANY  compute workloads are going to incur economic cost. However, capacity is being used more efficiently. Hardware physically dedicated to a single application is rarer, and even the largest engineered systems are more standardized so that they may one day benefit from Cloud approaches.

For small and medium sized applications, the overwhelming trend is to virtualize and run on  commodity hardware and operating system. Interfaces (interaction points for applications to exchange information with each other, generally in an automated way) are increasingly standardized. Hardware engineering is more and more independent of the application lifecycle; the trend is towards provding compute as a service, carefullly specified in terms of performance but NOT particular hardware.

Even 15 years ago, non-trivial web sites with database integration would be hosted by internal https://en.wikipedia.org/wiki/Platform_as_a_service[PaaS] clusters at major enterprises. Currently, it is a significant application indeed that merits its own systems engineering.

Instead, a variety of mechanisms (as covered in the previous chapter) enable the sharing of compute capacity, the raw material of application development. The fungibility and agility of these mechanisms increases the velocity of creation and evolution of applciation software.

===== Application architecture
